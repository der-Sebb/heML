{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erkennung von Herzversagen\n",
    "===\n",
    "Eine der vielen Möglichkeiten, in welchen personenbezogene Daten verarbeitet werden ist im Gesundheitswesen. So können zum Beispiel Modelle aus dem Maschinellen Lernen eingesetzt werden, um Krebs oder andere Krankheiten zu erkennen, welche aber wiederum persönliche Informationen des Patienten benötigen. Als Anwendungsfall wird in diesem Beispiel die Erkennung von Herzversagen anhand von verschiedenen Merkmalen getestet.<br />\n",
    "https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heNet import Network, FullyConnectedLayer, ActivationLayer\n",
    "from heNet import square, square_prime, sigmoid, sigmoid_prime, mse, mse_prime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tenseal as ts\n",
    "\n",
    "heart_csv = pd.read_csv(\"../data/heart.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die rohen Daten können aber nicht direkt zum Training verwendet werden und werden zuerst aufgeteilt, skaliert und transformiert in die korrekte Eingabeform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_dataframe = pd.get_dummies(heart_csv)\n",
    "\n",
    "y = heart_dataframe[\"HeartDisease\"]\n",
    "heart_dataframe.drop([\"HeartDisease\"], axis = 1, inplace = True, errors = \"ignore\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(heart_dataframe, y, test_size=0.25) # TODO\n",
    "\n",
    "scaler = MinMaxScaler() \n",
    "X_test_normal = scaler.fit_transform(X_test)\n",
    "\n",
    "X_train = np.array([[data] for data in scaler.fit_transform(X_train)])\n",
    "X_test = np.array([[data] for data in scaler.fit_transform(X_test)])\n",
    "y_train = np.array([[label] for label in y_train.to_numpy()])\n",
    "y_test =  np.array([[label] for label in y_test.to_numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die hier erstellte Architektur besitzt 3 Schichten mit zwei Quadratischen Aktivierungsfunktionen und einer Sigmoid Aktivierungsfunktion am Ende für das Training. Die Dimension der einzelnen Schichten nach der Eingabeschicht wurde niedrig gehalten, um die Größe der verarbeiteten Zahlen zu verringern. Ansonsten würden die Quadratischen Aktivierungsfunktionen zu einem Problem werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/500   error=0.269999\n",
      "epoch 101/500   error=0.092498\n",
      "epoch 201/500   error=0.080209\n",
      "epoch 301/500   error=0.073549\n",
      "epoch 401/500   error=0.066858\n"
     ]
    }
   ],
   "source": [
    "net = Network(100)\n",
    "net.add(FullyConnectedLayer(20, 10))\n",
    "net.add(ActivationLayer(square, square_prime))\n",
    "net.add(FullyConnectedLayer(10, 5))\n",
    "net.add(ActivationLayer(square, square_prime))\n",
    "net.add(FullyConnectedLayer(5, 1))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(X_train, y_train, epochs=500, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das trainierte Modell wird an dieser Stelle getestet auf einem Testdatensatz und produziert dabei entweder die Ausgabe, dass der Patient ein Risiko für Herzversagen hat oder eben nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im Testdatensatz wurden 180 von 230 richtig klassifiziert --> 0.78\n"
     ]
    }
   ],
   "source": [
    "out = net.predict(X_test)\n",
    "correct = 0\n",
    "for idx,_ in enumerate(out):\n",
    "    result = 1 if np.squeeze(out[idx]) > 0.5 else 0\n",
    "    if result == np.squeeze(y_test[idx]):\n",
    "        correct = correct + 1\n",
    "print(f\"Im Testdatensatz wurden {correct} von {len(out)} richtig klassifiziert --> {round(correct/len(out),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferenz auf verschlüsselten Daten\n",
    "---\n",
    "Nachdem das HE freundliche Modell erstellt wurde kann dieses nun auch auf den verschlüsselten Daten getestet werden. Verwendet wird dabei der zuvor getestete Teil des Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits_scale = 26\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=8192,\n",
    "    coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 31]\n",
    ")\n",
    "context.global_scale = pow(2, bits_scale)\n",
    "context.generate_galois_keys()\n",
    "\n",
    "e_X_test = np.array([[ts.ckks_vector(context, [value]) for value in data] for data in X_test_normal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes wird die letzte Schicht im Modell entfernt, da die verschlüsselten Daten nicht mit der normalen Sigmoid Funktion verrechnet werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.layers = net.layers[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der letzte und längste Schritt ist das eigentliche Testen der verschlüsselten Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im Testdatensatz wurden 180 von 230 richtig klassifiziert --> 0.78\n"
     ]
    }
   ],
   "source": [
    "out = net.predict(e_X_test)\n",
    "correct = 0\n",
    "for idx,_ in enumerate(out):\n",
    "    result = 1 if sigmoid(out[idx][0][0].decrypt()[0]) > 0.5 else 0\n",
    "    if result == np.squeeze(y_test[idx]):\n",
    "        correct = correct + 1\n",
    "print(f\"Im Testdatensatz wurden {correct} von {len(out)} richtig klassifiziert --> {round(correct/len(out),2)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a80ebf7ba738d5968b5f1bcd52e7a8cb27667057b121d5baaff5559180a4990f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('projektarbeit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
