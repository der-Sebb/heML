{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lineare Regression\n",
    "---\n",
    "Als ersten Anwendungsfall wird ein simples Maschinellen Lernen Verfahren betrachtet, die Lineare Regression. Hierbei wird ein mathematisches Modell durch Trainingsdaten erstellt, welches verwendet werden kann um ein ausgewähltes Feature vorherzusagen. Ein überschaubarer Datensatz für diese Aufgabe wäre zum Beispiel der Iris Datensatz. Dieser beinhaltet Features von drei verschiedenen Blumenarten, welche wiederum durch eine lineare Regression bestimmt werden können.\n",
    "<br />\n",
    "Zunächst muss dafür der Datensatz geladen und in die Trainings- und Testmenge aufgeteilt werden. Die beiden Mengen stehen dabei in einem 80% Trainingsdaten - 20% Testdaten Verhältnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset from sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliotheken Beispiel\n",
    "---\n",
    "Um einen Eindruck für eine Lineare Regression auf dem Iris Datensatz zu erhalten wird zuerst die Sklearn Implementierung ausprobiert. Die berechneten Abweichungen von den Ergebnissen können wiederum verglichen werden mit weiteren Tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.1584601230068247\n",
      "Mean Squared Error: 0.043573599004634006\n",
      "Mean Root Squared Error: 0.20874290168682144\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr.predict(X_test)\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, pred))\n",
    "print('Mean Root Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Scratch\n",
    "---\n",
    "Da die Implementierung aus Sklearn nicht jeden Datentyp unterstützt muss die Lineare Regression selbst implementiert werden. Der Grund dafür liegt in der homomorphen Verschlüsselung. Sobald eine beliebige Zahl verschlüsselt wurde, ist diese keine gewöhnliche Zahl mehr sonder ein verschlüsseltes Objekt und die meisten Bibliotheken erlauben als Parameter nur Zahlen beziehungsweise primitive Datentypen.\n",
    "<br />\n",
    "Für die Lineare Regression werden zwei Funktionen implementiert:\n",
    "* Fit: In dieser Funktion werden die Gewichte w in der Lineare Regression basierend auf den Trainingsdaten erstellt. Dies geschieht indem immer wieder mit den Gewichten Vorhersagen erstellt werden und verändert werden bis diese konvergieren.\n",
    "* Predict: In dieser Funktion wird die Vorhersage mit einer beliebigen Eingabe und den in der Predict Funktion berechneten Gewichte erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, y):\n",
    "\tregression = np.c_[x, np.ones(len(x))]\n",
    "\n",
    "\tweights = np.ones(regression.shape[1])\n",
    "\n",
    "\tnorma = 1\n",
    "\tlearning_rate = 0.00001\n",
    "\tepsilon = 0.9\n",
    "\tcount = 0\n",
    "\twhile(norma > epsilon):\n",
    "\t\tcount = count + 1\n",
    "\t\ty_pred = regression @ weights.T\n",
    "\t\tdw = regression.T @ (y - y_pred)\n",
    "\t\tnorma = np.sum(np.sqrt(np.square(dw)))\n",
    "\n",
    "\t\tweights = weights.T + (learning_rate * dw)\n",
    "\tprint(count)\n",
    "\treturn weights\n",
    "\n",
    "def predict(w, x):\n",
    "\treturn w[:-1] @ (np.array(x).T) + w[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem die Funktionen implementiert sind können die Gewichte erstellt werden mit den Trainingsdaten. Sobald diese berechnet sind wird ein Feature von den Testdaten vorhersagt. Dabei wird noch die Laufzeit der Vorhersage gemessen um später mit den anderen Tests verglichen zu werden.\n",
    "<br />\n",
    "Die erstellten Gewichte können in den Tests mit der homomorphen Verschlüsselung wieder verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7470\n",
      "Mean Absolute Error: 0.15791782248674335\n",
      "Mean Squared Error: 0.042219357807520355\n",
      "Mean Root Squared Error: 0.2054734966060595\n",
      "Prediction time for original: 0ms\n"
     ]
    }
   ],
   "source": [
    "weights = fit(X_train, y_train)\n",
    "\n",
    "s_predict = datetime.datetime.now()\n",
    "pred = predict(weights, X_test)\n",
    "e_predict = datetime.datetime.now()\n",
    "\n",
    "def meanError(y_test, pred):\n",
    "\tprint('Mean Absolute Error:', mean_absolute_error(y_test, pred))\n",
    "\tprint('Mean Squared Error:', mean_squared_error(y_test, pred))\n",
    "\tprint('Mean Root Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))\n",
    "\n",
    "meanError(y_test, pred)\n",
    "\n",
    "print(f\"Prediction time for original: {int((e_predict-s_predict).total_seconds() * 1000)}ms\")\n",
    "\n",
    "def timer(encryptTime, predictTime, decryptTime):\n",
    "\tprint(f\"Encryption time: {int(encryptTime.total_seconds() * 1000)}ms\")\n",
    "\tprint(f\"Prediction time: {int(predictTime.total_seconds() * 1000)}ms\")\n",
    "\tprint(f\"Decryption time: {int(decryptTime.total_seconds() * 1000)}ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die berechneten Abweichung zwischen den Vorhersagen und den tatsächlichen Features sind ähnlich zu den Ergebnissen der Sklearn Implementierung und weisen erst ab der 3. Nachkommastelle Unterschiede auf. Die eigene Implementierung scheint dadurch korrekt zu funktionieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorhersagen auf verschlüsselten Daten\n",
    "===\n",
    "In den folgenden zwei Beispielen werden die mit unverschlüsselten Daten trainierten Gewichte angewendet auf verschlüsselte Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verschlüsselung mit Pyfhel\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pyfhel import Pyfhel\n",
    "\n",
    "pyfhel = Pyfhel()\n",
    "pyfhel.contextGen(p=65537)\n",
    "\n",
    "pyfhel.keyGen()\n",
    "\n",
    "def encrypt(data):\n",
    "    return [[pyfhel.encryptFrac(feature) for feature in item] for item in data]\n",
    "\n",
    "def decrypt(data):\n",
    "    return [pyfhel.decryptFrac(item) for item in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für diese Bibliothek muss die predict Funktion etwas umgeschrieben werden, da die Matrizenmultiplikation Operation nicht funktioniert zwischen Skalaren und verschlüsselten Objekten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictPyfhel(w, x):\n",
    "    transX = np.array(x).T\n",
    "    result = []\n",
    "    for i in range(transX.shape[1]):\n",
    "        for j in range(transX.shape[0]):\n",
    "            scaledFeature = transX[j][i] * w[j]\n",
    "            if len(result) == i:\n",
    "                result.append(scaledFeature)\n",
    "            else:\n",
    "                result[i] = result[i] + scaledFeature\n",
    "    return np.array(result) + w[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als letzter Schritt werden alle Testdaten verschlüsselt, die Vorhersage erzeugt und das Ergebnis entschlüsselt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.1579178223464017\n",
      "Mean Squared Error: 0.04221935761486088\n",
      "Mean Root Squared Error: 0.20547349613724122\n",
      "Encryption time: 121ms\n",
      "Prediction time: 19ms\n",
      "Decryption time: 4ms\n"
     ]
    }
   ],
   "source": [
    "s_encrypt = datetime.datetime.now()\n",
    "eX_test = encrypt(X_test)\n",
    "e_encrypt = datetime.datetime.now()\n",
    "\n",
    "s_predict = datetime.datetime.now()\n",
    "ePred = predictPyfhel(weights, eX_test)\n",
    "e_predict = datetime.datetime.now()\n",
    "\n",
    "s_decrypt = datetime.datetime.now()\n",
    "cryptPred = decrypt(ePred)\n",
    "e_decrypt = datetime.datetime.now()\n",
    "\n",
    "meanError(y_test, cryptPred)\n",
    "timer(e_encrypt-s_encrypt, e_predict-s_predict, e_decrypt-s_decrypt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Funktionalität: Ergebnisse sind fast identisch zum Original (Abweichungen in der Gleitkommarepräsentation)\n",
    "* Laufzeit: Fast gleich schnell wie die Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verschlüsselung mit Paillier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phe import paillier\n",
    "\n",
    "public_key, private_key = paillier.generate_paillier_keypair()\n",
    "\n",
    "def encrypt(data):\n",
    "    return [[public_key.encrypt(feature) for feature in item] for item in data]\n",
    "\n",
    "def decrypt(data):\n",
    "    return [private_key.decrypt(item) for item in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Paillier Bibliothek in Python muss keine gesonderte predict Funktion implementiert werden, da die Matrizenmultiplikation möglich ist. Dadurch müssen nur noch die Daten verschlüsselt, die Vorhersage erzeugt und das Ergebnis entschlüsselt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.15791782248674335\n",
      "Mean Squared Error: 0.042219357807520355\n",
      "Mean Root Squared Error: 0.2054734966060595\n",
      "Encryption time: 9872ms\n",
      "Prediction time: 518ms\n",
      "Decryption time: 696ms\n"
     ]
    }
   ],
   "source": [
    "s_encrypt = datetime.datetime.now()\n",
    "eX_test = encrypt(X_test)\n",
    "e_encrypt = datetime.datetime.now()\n",
    "\n",
    "s_predict = datetime.datetime.now()\n",
    "ePred = predict(weights, eX_test)\n",
    "e_predict = datetime.datetime.now()\n",
    "\n",
    "s_decrypt = datetime.datetime.now()\n",
    "cryptPred = decrypt(ePred)\n",
    "e_decrypt = datetime.datetime.now()\n",
    "\n",
    "meanError(y_test, cryptPred)\n",
    "timer(e_encrypt-s_encrypt, e_predict-s_predict, e_decrypt-s_decrypt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Funktionalität: Identisches Ergebnis zu der unverschlüsselten Version\n",
    "* Laufzeit: Benötigt deutlich länger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training auf verschlüsselten Daten\n",
    "===\n",
    "Für das Training auf verschlüsselten Daten müssen auch die Gewichte der Linearer Regression verschlüsselt werden. Nachdem Training können die Gewichte wieder entschlüsselt und wieder für die Inferenz genutzt werden. Hierfür verschlüsselt der Datenbesitzer seine Daten und verschickt diese zusammen mit dem öffentlichen Schlüssel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tenseal as ts\n",
    "\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()\n",
    "\n",
    "def encryptX(data, context):\n",
    "    return [[ts.ckks_vector(context, [feature]) for feature in item] for item in data]\n",
    "\n",
    "def encryptY(data, context):\n",
    "    return [ts.ckks_vector(context, [label]) for label in data]\n",
    "\n",
    "def decrypt(data):\n",
    "    return [item.decrypt() for item in data]\n",
    "\n",
    "seal_x_train = encryptX(X_train,ctx_training)\n",
    "seal_y_train = encryptY(y_train,ctx_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Netz zu trainieren gibt es zwei Möglichkeiten:\n",
    "* Nach jedem Trainingsschritt können die Gewichte entschlüsselt werden, durch den Besitzer des zugehörigen privaten Schlüssels, um dann wieder verschlüsselt zu werden. Dies würde erlauben die Berechnung so oft wie gewünscht durchzuführen. Das Problem hierbei ist, dass dies ein großer Zeit und Rechenaufwand mit sich bringt.\n",
    "* Die Gewichte müssen aber nicht nach jedem Trainingsschritt entschlüsselt werden und es kann für eine begrenzte Anzahl von Operationen trainiert werden. Diese Variante verringert aber die erreichbare Genauigkeit der trainierten Gewichte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kein Ausstausch mit Datenbesitzer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um den Aufwand für den Datenbesitzer niedrig zu halten wird die zweite Variante implementiert und getestet. Hierfür wird die fit Funktion verändert, da nicht alle Vorgänge durchführbar sind mit verschlüsselten Daten. So können zum Beispiel die Gewichte nicht solange optimiert werden bis diese konvergieren, weshalb es nur wenige Trainingsphasen geben wird. Damit das Training trotzdem erfolgreich ist ist es hielfreich verschiedene Lernraten auszuprobieren, um die Gewichte gut zu approximieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = [2, 1, 0.1, 0.01, 0.007, 0.003, 0.002, 0.001, 0.0009, 0.0007, 0.0003, 0.0001, 0.00001]\n",
    "\n",
    "def fit(x, y, context):\n",
    "\tregression = np.c_[x, np.ones(len(x))]\n",
    "\n",
    "\tweights = np.ones(regression.shape[1])\n",
    "\te_weights = np.array(encryptY(weights, context))\n",
    "\n",
    "\tall_weights = []\n",
    "\tfor learning_rate in hyperparameter:\n",
    "\t\thyper_weights = e_weights\n",
    "\t\tfor i in range(2):\n",
    "\t\t\ty_pred = regression @ hyper_weights.T\n",
    "\t\t\tdw = regression.T @ (y - y_pred)\n",
    "\t\t\thyper_weights = hyper_weights.T + (learning_rate * dw)\n",
    "\n",
    "\t\tall_weights.append((learning_rate, hyper_weights))\n",
    "\n",
    "\treturn all_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Training gibt also eine Liste an verschiedenen Gewichten aus für die unterschiedlichen Lernraten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = fit(seal_x_train, seal_y_train, ctx_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_weights = [[e_value.decrypt()[0] for e_value in e_tuple[1]] for e_tuple in all_weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die verschiedenen Versionen der Gewichte können nun einzelnen geprüft werden auf dem Testdatensatz. Dadurch kann bestimmt werden welche Lernrate für diese Aufgabe die Beste ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Gewichte sind die mit der Learning rate von 0.002\n"
     ]
    }
   ],
   "source": [
    "min = []\n",
    "for idx, learning_rate in enumerate(hyperparameter):\n",
    "    result = predict(e_weights[idx], X_test)\n",
    "    min.append(np.sqrt(mean_squared_error(y_test, result)))\n",
    "best_weight_idx = np.argmin(min)\n",
    "print(f\"Beste Gewichte sind die mit der Learning rate von {hyperparameter[best_weight_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die besten trainierten Gewichte haben eine höhere Abweichung als die Gewichte der unverschlüsselten Modelle. Es kommt aber nahe dran und kann noch weiter verbessert werden mit mehr Trainingsiterationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eingabe: [ 1.64384411 -0.13197948  1.16062026  0.52740629]\n",
      "Wahres Ergebnis: 2\n",
      "Ergebnis aus dem verschlüsselt trainierten Modell: 1.5735141565652482\n",
      "Ergebnis aus dem nicht verschlüsselt trainierten Modell: 1.5767759592337507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "index = randint(0, len(X_test)-1)\n",
    "print(f\"\"\"\n",
    "Eingabe: {X_test[index]}\n",
    "Wahres Ergebnis: {y_test[index]}\n",
    "Ergebnis aus dem verschlüsselt trainierten Modell: {predict(e_weights[best_weight_idx], X_test[index])}\n",
    "Ergebnis aus dem nicht verschlüsselt trainierten Modell: {predict(weights, X_test[index])}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.31726084294777773\n",
      "Mean Squared Error: 0.1310889495171555\n",
      "Mean Root Squared Error: 0.3620620796454049\n"
     ]
    }
   ],
   "source": [
    "result = predict(e_weights[best_weight_idx], X_test)\n",
    "meanError(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Unterschied im einzelnen Beispiel ist minimal und auch die eizelnen Metriken zeigen auf, dass das mit verschlüsselten Daten trainierte Modell zwar schlechter ist als die vorherig trainierten Modelle aber trotzdem in einem akzeptablen Bereich liegt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Austausch mit dem Datenbesitzer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die erste Variante leidet unter den begrenzenten Operationen auf den verschlüsselten Gewichten. Vor allem wird dabei die Genauigkeit zugunsten der Laufzeit geopfert. In der zweiten Variante werden die Gewichte nach jeder Veränderung an den Datenbesitzer geschickt, damit diese entschlüsselt und neu verschlüsselt werden können. Damit ist eine unbegrenzte Anzahl an Operationen möglich und es kann fast wie auf unverschlüsselten Daten trainiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tenseal as ts\n",
    "\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 40]\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()\n",
    "\n",
    "seal_x_train = encryptX(X_train,ctx_training)\n",
    "seal_y_train = encryptY(y_train,ctx_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Während dem Training wird also nach jedem Epoch die Gewichte dem Datenbesitzer zugesendet. Dieser ent- und verschlüsselt diese wieder mit den gleichen Parameter wie am Anfang des Trainings. Dieser Vorgang wird mit dem Aufruf der folgenden Methode simuliert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_receive_weights(e_weights):\n",
    "\tweights = [item.decrypt() for item in e_weights]\n",
    "\treturn np.array([ts.ckks_vector(ctx_training, label) for label in weights])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der große Unterschied zum unverschlüsselten Training ist dabei, dass wir nicht aus der Ableitung der Gewichte ablesen können wie weit die Funktion noch optimiert werden muss. Dies liegt daran, da wir davon ausgehen, dass die Person, welche das Training ausführt, die entschlüsselten Gewichte erst zugesendet bekommt sobald das Training abgeschlossen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, y, epochs, learning_rate=0.00001):\n",
    "\tregression = np.c_[x, np.ones(len(x))]\n",
    "\n",
    "\tweights = np.ones(regression.shape[1])\n",
    "\te_weights = np.array(encryptY(weights, ctx_training))\n",
    "\n",
    "\tfor _ in range(epochs):\n",
    "\t\ty_pred = regression @ e_weights.T\n",
    "\t\tdw = regression.T @ (y - y_pred)\n",
    "\t\te_weights = e_weights.T + (learning_rate * dw)\n",
    "\t\te_weights = send_receive_weights(e_weights)\n",
    "\n",
    "\treturn [item.decrypt() for item in e_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_weights = fit(seal_x_train, seal_y_train, 200, 0.0001)\n",
    "e_weights = [e_weight[0] for e_weight in e_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eingabe: [-1.26418478 -0.13197948 -1.34022653 -1.18381211]\n",
      "Wahres Ergebnis: 0\n",
      "Ergebnis aus dem verschlüsselt trainierten Modell: -0.0015522208458345066\n",
      "Ergebnis aus dem nicht verschlüsselt trainierten Modell: 0.04208134636702654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = randint(0, len(X_test)-1)\n",
    "print(f\"\"\"\n",
    "Eingabe: {X_test[index]}\n",
    "Wahres Ergebnis: {y_test[index]}\n",
    "Ergebnis aus dem verschlüsselt trainierten Modell: {predict(e_weights, X_test[index])}\n",
    "Ergebnis aus dem nicht verschlüsselt trainierten Modell: {predict(weights, X_test[index])}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.17206092527074002\n",
      "Mean Squared Error: 0.06821842140262571\n",
      "Mean Root Squared Error: 0.2611865643608524\n"
     ]
    }
   ],
   "source": [
    "result = predict(e_weights, X_test)\n",
    "meanError(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie zu sehen ist an den Ergebnissen hat das mit Hilfe der anderen Variante trainierte Modell eine höhere Genauigkeit. Dies wäre also ein Kompromiss zwischen der Genauigkeit und der Laufzeit, da das immer wieder aufs neue verschlüsseln der Gewichte sehr aufwändig ist."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f7bcc9c9e9fc7020bbd4d78b5067a4b842b19b8327d3657c3117d34f6877e4d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('projektarbeit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
