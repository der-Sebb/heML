{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuronale Netze Tests\n",
    "===\n",
    "Die in dem XOR Neural Net Notebook erstellten Netze wurden in verschiedenen Klassen und Funktionen zusammengefasst. Deswegen wird diese Implementierung anhand des XOR Beispiel und des Iris Datensatz ausprobiert. Verwendet wird in den jeweiligen Architekturen die bereits getestete Idee der Quadratischen Funktion als Aktivierungsfunktion zusammen mit einer Sigmoid Funktion in der Ausgabenschicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.heNet import Network, FullyConnectedLayer, ActivationLayer\n",
    "from util.heNet import square, square_prime, sigmoid, sigmoid_prime, binary_cross_entropy, binary_cross_entropy_prime\n",
    "import numpy as np\n",
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
    "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "net.add(FullyConnectedLayer(2, 2))\n",
    "net.add(ActivationLayer(square, square_prime))\n",
    "net.add(FullyConnectedLayer(2, 1))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "\n",
    "net.use(binary_cross_entropy, binary_cross_entropy_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.06464641]]), array([[0.9856887]]), array([[0.98586713]]), array([[0.06312294]])]\n"
     ]
    }
   ],
   "source": [
    "net.fit(x_train, y_train, epochs=100, learning_rate=1, minibatch=4)\n",
    "\n",
    "out = net.predict(x_train)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Test wurde die gleiche Architektur verwendet und es erzeugt die korrekten Ausgaben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris Datensatz\n",
    "---\n",
    "Als nächster Test wird der Datensatz aus der Linear Regression verwendet. In diesem Fall wird aber die Art der Blumen anhand der Merkmalen vorhergesagt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "def transform(data):\n",
    "    return np.array([[row] for row in data])\n",
    "\n",
    "X_train = transform(X_train)\n",
    "X_test = transform(X_test)\n",
    "y_train = transform(y_train)\n",
    "y_test = transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die verwendete Architektur für die Iris Aufgabe besteht wie für XOR aus der gleichen Anzahl an Schichten, aber hat eine andere Dimension, da es unterschiedlich viele Features gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(debug=None)\n",
    "net.add(FullyConnectedLayer(4, 4))\n",
    "net.add(ActivationLayer(square, square_prime))\n",
    "net.add(FullyConnectedLayer(4, 3))\n",
    "net.add(ActivationLayer(square, square_prime))\n",
    "\n",
    "net.use(binary_cross_entropy, binary_cross_entropy_prime)\n",
    "net.fit(X_train, y_train, epochs=10, learning_rate=0.002, minibatch=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das trainierte Modell kann die Klassen der Blumen des Testdatensatz nun vorhersagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im Testdatensatz wurden 29 von 30 richtig klassifiziert --> 0.97\n"
     ]
    }
   ],
   "source": [
    "outHE = net.predict(X_test)\n",
    "correct = 0\n",
    "for idx,_ in enumerate(outHE):\n",
    "    if np.argmax(np.squeeze(outHE[idx])) == np.argmax(np.squeeze(y_test[idx])):\n",
    "        correct = correct + 1\n",
    "print(f\"Im Testdatensatz wurden {correct} von {len(outHE)} richtig klassifiziert --> {round(correct/len(outHE),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das HE freundliche Modell hat fast alle der unverschlüsselten Daten korrekt klassifiziert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Vergleich wird noch ein \"normales\" Netz trainiert, das aus der gleichen Anzahl an Schichten besteht aber anstatt der quadratischen Aktivierungsfunktion die Sigmoid Aktivierungsfunktion verwendet in der Versteckten Schicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(debug=None)\n",
    "net.add(FullyConnectedLayer(4, 4))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "net.add(FullyConnectedLayer(4, 3))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "\n",
    "net.use(binary_cross_entropy, binary_cross_entropy_prime)\n",
    "net.fit(X_train, y_train, epochs=10, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im Testdatensatz wurden 30 von 30 richtig klassifiziert --> 1.0\n"
     ]
    }
   ],
   "source": [
    "outN = net.predict(X_test)\n",
    "correct = 0\n",
    "for idx,_ in enumerate(outN):\n",
    "    if np.argmax(np.squeeze(outN[idx])) == np.argmax(np.squeeze(y_test[idx])):\n",
    "        correct = correct + 1\n",
    "print(f\"Im Testdatensatz wurden {correct} von {len(outN)} richtig klassifiziert --> {round(correct/len(outN),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit beider Modelle ist ähnlich und weißt darauf hin, dass das HE freundliche Modell nicht schlechter ist als die übliche Architektur."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f7bcc9c9e9fc7020bbd4d78b5067a4b842b19b8327d3657c3117d34f6877e4d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('projektarbeit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
