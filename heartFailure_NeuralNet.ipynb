{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erkennung von Herzversagen\n",
    "===\n",
    "Eine der vielen Möglichkeiten, in welchen personenbezogene Daten verarbeitet werden ist im Gesundheitswesen. So können zum Beispiel Modelle aus dem Maschinellen Lernen eingesetzt werden, um Krebs oder andere Krankheiten zu erkennen, welche aber wiederum persönliche Informationen des Patienten benötigen. Als Anwendungsfall wird in diesem Beispiel die Erkennung von Herzversagen anhand von verschiedenen Merkmalen getestet.<br />\n",
    "https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.heNet import Network, FullyConnectedLayer, ActivationLayer\n",
    "from util.heNet import square, square_prime, sigmoid, sigmoid_prime, binary_cross_entropy, binary_cross_entropy_prime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tenseal as ts\n",
    "\n",
    "heart_csv = pd.read_csv(\"../data/heart.csv\")\n",
    "\n",
    "heart_dataframe = pd.get_dummies(heart_csv)\n",
    "\n",
    "y = heart_dataframe[\"HeartDisease\"]\n",
    "heart_dataframe.drop([\"HeartDisease\"], axis = 1, inplace = True, errors = \"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vergleich mit einer PyTorch Architektur\n",
    "---\n",
    "Um die HE freundlichen Implementierung zu vergleichen mit einer etablierten Bibliothek wird ein Netz mit PyTorch gebaut und evaluiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TorchNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(TorchNet, self).__init__()\n",
    "    self.one = nn.Linear(20, 40)\n",
    "    self.output = nn.Linear(40, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.one(x)\n",
    "    x = torch.sigmoid(x)\n",
    "    x = self.output(x)\n",
    "    x = torch.sigmoid(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HE Architektur Vergleich\n",
    "---\n",
    "Die hier erstellte Architektur besitzt 2 Schichten mit einer Quadratischen Aktivierungsfunktionen und einer Sigmoid Aktivierungsfunktion am Ende für das Training. Die Dimension der einzelnen Schichten nach der Eingabeschicht wurde niedrig gehalten, um die Größe der verarbeiteten Zahlen zu verringern. Ansonsten würden die Quadratischen Aktivierungsfunktionen zu einem Problem werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net = Network(debug=None)\n",
    "test_net.add(FullyConnectedLayer(20, 10))\n",
    "test_net.add(ActivationLayer(square, square_prime))\n",
    "test_net.add(FullyConnectedLayer(10, 1))\n",
    "test_net.add(ActivationLayer(sigmoid, sigmoid_prime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation\n",
    "---\n",
    "Nun können beide Architekturen miteinander verglichen werden indem beide die selbe Cross Validation durchlaufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation HE Architektur --> 0.855\n",
      "Cross Validation PyTorch Architektur --> 0.865\n"
     ]
    }
   ],
   "source": [
    "from CrossValidation import cross_validate_he_torch\n",
    "\n",
    "he_acc_sum, torch_acc_sum = cross_validate_he_torch(he_net=test_net, torch=TorchNet, heart_dataframe=heart_dataframe, label=y)\n",
    "\n",
    "print(f\"Cross Validation HE Architektur --> {round(np.array(he_acc_sum).mean(),3)}\")\n",
    "print(f\"Cross Validation PyTorch Architektur --> {round(np.array(torch_acc_sum).mean(),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training eines HE freundlichen Modells\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die durchschnittliche Genauigkeit ähnlich zur Genauigkeit des PyTorch Modells ist wird nun erneut ein HE freundliches Netz trainiert, welches eingesetzt wird für die Inferenzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toNp(value_list):\n",
    "    return np.array([[data] for data in value_list])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(heart_dataframe, y, test_size=0.25) # TODO\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_test_normal = train_scaler.transform(X_test)\n",
    "X_train = train_scaler.transform(X_train)\n",
    "X_test = train_scaler.transform(X_test)\n",
    "\n",
    "X_train = toNp(X_train)\n",
    "X_test = toNp(X_test)\n",
    "y_train = toNp(toNp(y_train.to_numpy()))\n",
    "y_test =  toNp(toNp(y_test.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10\n",
      "epoch 2/10\n",
      "epoch 3/10\n",
      "epoch 4/10\n",
      "epoch 5/10\n",
      "epoch 6/10\n",
      "epoch 7/10\n",
      "epoch 8/10\n",
      "epoch 9/10\n",
      "epoch 10/10\n",
      "Im Testdatensatz wurden 198 von 230 richtig klassifiziert --> 0.861\n"
     ]
    }
   ],
   "source": [
    "net = Network(1)\n",
    "net.add(FullyConnectedLayer(20, 10))\n",
    "net.add(ActivationLayer(square, square_prime))\n",
    "net.add(FullyConnectedLayer(10, 1))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "\n",
    "net.use(binary_cross_entropy, binary_cross_entropy_prime)\n",
    "net.fit(X_train, y_train, epochs=10, minibatch=8, learning_rate=0.001)\n",
    "\n",
    "out = net.predict(X_test)\n",
    "correct = 0\n",
    "for idx,_ in enumerate(out):\n",
    "    result = 1 if np.squeeze(out[idx]) > 0.5 else 0\n",
    "    if result == np.squeeze(y_test[idx]):\n",
    "        correct = correct + 1\n",
    "print(f\"Im Testdatensatz wurden {correct} von {len(out)} richtig klassifiziert --> {round(correct/len(out),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferenz auf verschlüsselten Daten\n",
    "---\n",
    "Nachdem das HE freundliche Modell erstellt wurde kann dieses nun auch auf den verschlüsselten Daten getestet werden. Verwendet wird dabei der zuvor getestete Teil des Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits_scale = 26\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=8192,\n",
    "    coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, 31]\n",
    ")\n",
    "context.global_scale = pow(2, bits_scale)\n",
    "context.generate_galois_keys()\n",
    "\n",
    "e_X_test = np.array([[ts.ckks_vector(context, [value]) for value in data] for data in X_test_normal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes wird die letzte Schicht im Modell entfernt, da die verschlüsselten Daten nicht mit der normalen Sigmoid Funktion verrechnet werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.layers = net.layers[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der letzte und längste Schritt ist das eigentliche Testen der verschlüsselten Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im Testdatensatz wurden 198 von 230 richtig klassifiziert --> 0.861\n"
     ]
    }
   ],
   "source": [
    "e_out = net.predict(e_X_test)\n",
    "correct = 0\n",
    "d_out = []\n",
    "for idx,_ in enumerate(e_out):\n",
    "    result = 1 if sigmoid(e_out[idx][0][0].decrypt()[0]) > 0.5 else 0\n",
    "    d_out.append(result)\n",
    "    if result == np.squeeze(y_test[idx]):\n",
    "        correct = correct + 1\n",
    "print(f\"Im Testdatensatz wurden {correct} von {len(e_out)} richtig klassifiziert --> {round(correct/len(e_out),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Positiv: Genauigkeit zwischen unverschlüsselte und verschlüsselte Test sind gleich\n",
    "* Negativ: Laufzeit hängt stark von der Architektur und Größe der verschlüsselten Objekte ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Vergleich wird noch überprüft ob jede Eingabe auch die gleiche Ausgabe produziert hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "u_out = [1 if np.squeeze(value) > 0.5 else 0 for value in out]\n",
    "print(u_out == d_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training mit verschlüsselten Daten\n",
    "===\n",
    "Für das Training des Modells auf den verschlüsselten Daten wird der zweite Ansatz des Trainings der Linearen Regression auf verschlüsselten Daten verwendet. Das bedeutet, dass an dieser Stelle eine interaktive Variante dargestellt wird zwischen dem Datenbesitzer und den ML Experten, die das Netz trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heNet import EncryptedActivationLayer, EncryptedFullyConnectedLayer\n",
    "\n",
    "def encrypted_training(context):\n",
    "    net = Network(debug=2)\n",
    "    net.add(EncryptedFullyConnectedLayer(20, 10, context))\n",
    "    net.add(EncryptedActivationLayer(square, square_prime, context))\n",
    "    net.add(EncryptedFullyConnectedLayer(10, 1, context))\n",
    "    net.add(EncryptedActivationLayer(square, square_prime, context))\n",
    "\n",
    "    net.use(binary_cross_entropy, binary_cross_entropy_prime)\n",
    "\n",
    "    net.crypt_fit(X_train, y_train, epochs=10, minibatch=8, learning_rate=0.0009, context=context)\n",
    "    return net\n",
    "\n",
    "def encrypted_predict(net):\n",
    "    outN = net.predict(X_test)\n",
    "    correct = 0\n",
    "    for idx,result in enumerate(outN):\n",
    "        result = 1 if result > 0.5 else 0\n",
    "        if result == np.squeeze(y_test[idx]):\n",
    "            correct = correct + 1\n",
    "    print(f\"Im Testdatensatz wurden {correct} von {len(outN)} richtig klassifiziert --> {round(correct/len(outN),3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10\n",
      "epoch 3/10\n",
      "epoch 5/10\n",
      "epoch 7/10\n",
      "epoch 9/10\n"
     ]
    }
   ],
   "source": [
    "poly_mod_degree = 2 ** 12\n",
    "bits_scale = 20\n",
    "\n",
    "coeff_mod_bit_sizes=[40, bits_scale, 40]\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "\n",
    "context.global_scale = pow(2, bits_scale)\n",
    "context.generate_galois_keys()\n",
    "\n",
    "net = encrypted_training(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im Testdatensatz wurden 193 von 230 richtig klassifiziert --> 0.839\n"
     ]
    }
   ],
   "source": [
    "encrypted_predict(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Training mit niedrigen Verschlüsselungseinstellungen und erneute Verschlüsselung nach jeder verschlüsselten Multiplikation hat 116 Minuten gedauert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im Testdatensatz wurden 193 von 230 richtig klassifiziert --> 0.839\n"
     ]
    }
   ],
   "source": [
    "test = Network()\n",
    "test.add(FullyConnectedLayer(20, 10))\n",
    "test.add(ActivationLayer(square, square_prime))\n",
    "test.add(FullyConnectedLayer(10, 1))\n",
    "test.add(ActivationLayer(square, square_prime))\n",
    "\n",
    "test.use(binary_cross_entropy, binary_cross_entropy_prime)\n",
    "test.fit(X_train, y_train, epochs=10, minibatch=8, learning_rate=0.0009)\n",
    "\n",
    "out = test.predict(X_test)\n",
    "correct = 0\n",
    "for idx,_ in enumerate(out):\n",
    "    result = 1 if np.squeeze(out[idx]) > 0.5 else 0\n",
    "    if result == np.squeeze(y_test[idx]):\n",
    "        correct = correct + 1\n",
    "print(f\"Im Testdatensatz wurden {correct} von {len(out)} richtig klassifiziert --> {round(correct/len(out),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit beider Modelle ist aber nicht durch die Dauer oder den verschlüsselten Daten beeinflusst und wird nur von der Modellarchitektur zurückgehalten."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f7bcc9c9e9fc7020bbd4d78b5067a4b842b19b8327d3657c3117d34f6877e4d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('projektarbeit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
