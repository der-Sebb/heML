{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR Training mit verschlüsselten Daten\n",
    "---\n",
    "Nun soll ein XOR Modell trainiert mit verschlüsselten Daten werden. Dafür muss in der Inferenz verwendeten Architektur alle Aktivierungsfunktionen mit der quadratischen Aktivierungsfunktion ersetzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.heNet import Network, FullyConnectedLayer, ActivationLayer\n",
    "from util.heNet import square, square_prime, binary_cross_entropy, binary_cross_entropy_prime\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "\n",
    "poly_mod_degree = 2 ** 13\n",
    "bits_scale = 40\n",
    "\n",
    "coeff_mod_bit_sizes=[60, bits_scale, 60]\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "\n",
    "context.global_scale = pow(2, bits_scale)\n",
    "context.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.heNet import EncryptedActivationLayer, EncryptedFullyConnectedLayer\n",
    "\n",
    "net = Network(25)\n",
    "net.add(EncryptedFullyConnectedLayer(2, 2, context))\n",
    "net.add(EncryptedActivationLayer(square, square_prime, context))\n",
    "net.add(EncryptedFullyConnectedLayer(2, 1, context))\n",
    "net.add(EncryptedActivationLayer(square, square_prime, context))\n",
    "\n",
    "net.use(binary_cross_entropy, binary_cross_entropy_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
    "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100\n",
      "epoch 26/100\n",
      "epoch 51/100\n",
      "epoch 76/100\n"
     ]
    }
   ],
   "source": [
    "net.crypt_fit(x_train, y_train, epochs=100, learning_rate=0.1, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.0645173]]), array([[0.79783051]]), array([[0.81424527]]), array([[0.02962624]])]\n"
     ]
    }
   ],
   "source": [
    "out = net.predict(x_train)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man sind die Ausgaben wie erwartet in der Form von 0 1 1 0 (die Ausgaben weichen etwas ab aber wären durch eine Fallunterscheid mit 0.5 als Grenze immer noch richtig) und somit hat das Modell die Abbildung eines XOR Gatters mit den verschlüsselten Daten gelernt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris Training mit verschlüsselten Daten\n",
    "---\n",
    "In diesem Test wird der interaktive Ansatz auf dem Iris Datensatz ausprobiert, um ein Modell auf den verschlüsselten Daten zu trainieren das die Klasse der Blumen vorhersagen kann. Hierfür wird wieder der benötigte Datensatz zuerst geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "def transform(data):\n",
    "    return np.array([[row] for row in data])\n",
    "\n",
    "X_train = transform(X_train)\n",
    "X_test = transform(X_test)\n",
    "y_train = transform(y_train)\n",
    "y_test = transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das fürs Training verwendete Modell in der Inferenz wird hier von der Architektur her wieder verwendet. Nur muss wie bereits erwähnt die letzte Aktivierungsfunktion ersetzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypted_training(context):\n",
    "    net = Network(debug=5)\n",
    "    net.add(EncryptedFullyConnectedLayer(4, 4, context))\n",
    "    net.add(EncryptedActivationLayer(square, square_prime, context))\n",
    "    net.add(EncryptedFullyConnectedLayer(4, 3, context))\n",
    "    net.add(EncryptedActivationLayer(square, square_prime, context))\n",
    "\n",
    "    net.use(binary_cross_entropy, binary_cross_entropy_prime)\n",
    "\n",
    "    net.crypt_fit(X_train, y_train, epochs=10, learning_rate=0.002, minibatch=8, context=context)\n",
    "\n",
    "    outN = net.predict(X_test)\n",
    "    correct = 0\n",
    "    for idx,_ in enumerate(outN):\n",
    "        if np.argmax(np.squeeze(outN[idx])) == np.argmax(np.squeeze(y_test[idx])):\n",
    "            correct = correct + 1\n",
    "    print(f\"Im Testdatensatz wurden {correct} von {len(outN)} richtig klassifiziert --> {round(correct/len(outN),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird ein kleiner Verschlüsselungskontext gewählt, um schnelle Berechnungen in den Schichten zu ermöglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10\n",
      "epoch 6/10\n",
      "Im Testdatensatz wurden 29 von 30 richtig klassifiziert --> 0.97\n"
     ]
    }
   ],
   "source": [
    "poly_mod_degree = 2 ** 13\n",
    "bits_scale = 40\n",
    "\n",
    "coeff_mod_bit_sizes=[60, bits_scale, 60]\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "\n",
    "context.global_scale = pow(2, bits_scale)\n",
    "context.generate_galois_keys()\n",
    "\n",
    "encrypted_training(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit dieses Modells ist etwas schlechter als das unverschlüsselte Modell (während der Inferenz), vermutlich weil die Lernrate niedriger ist und es dadurch nicht perfekt optimiert ist. Die Lernrate muss aber kleiner sein, denn ansonsten geraten die Werte durch die quadratischen Aktivierungsfunktionen auser Kontrolle  (beziehungsweise die Gewichte im Netz werden zu groß)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f7bcc9c9e9fc7020bbd4d78b5067a4b842b19b8327d3657c3117d34f6877e4d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('projektarbeit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
