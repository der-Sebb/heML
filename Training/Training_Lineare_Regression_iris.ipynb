{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training auf verschlüsselten Daten\n",
    "===\n",
    "Zuerst werden für das Training alle Daten geladen und notwendigen Funktion definiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2)\n",
    "\n",
    "def fit(x, y):\n",
    "\tregression = np.c_[x, np.ones(len(x))]\n",
    "\n",
    "\tweights = np.ones(regression.shape[1])\n",
    "\n",
    "\tnorma = 1\n",
    "\tlearning_rate = 0.00001\n",
    "\tepsilon = 0.9\n",
    "\twhile(norma > epsilon):\n",
    "\t\ty_pred = regression @ weights.T\n",
    "\t\tdw = regression.T @ (y - y_pred)\n",
    "\t\tnorma = np.sum(np.sqrt(np.square(dw)))\n",
    "\n",
    "\t\tweights = weights.T + (learning_rate * dw)\n",
    "\treturn weights\n",
    "\n",
    "def predict(w, x):\n",
    "\treturn w[:-1] @ (np.array(x).T) + w[-1]\n",
    "\n",
    "weights = fit(X_train, y_train)\n",
    "\n",
    "def meanError(y_test, pred):\n",
    "\tprint('Mean Absolute Error:', mean_absolute_error(y_test, pred))\n",
    "\tprint('Mean Squared Error:', mean_squared_error(y_test, pred))\n",
    "\tprint('Mean Root Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das Training auf verschlüsselten Daten müssen auch die Gewichte der Linearer Regression verschlüsselt werden. Nachdem Training können die Gewichte wieder entschlüsselt und wieder für die Inferenz genutzt werden. Hierfür verschlüsselt der Datenbesitzer seine Daten und verschickt diese zusammen mit dem öffentlichen Schlüssel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()\n",
    "\n",
    "def encryptX(data, context):\n",
    "    return [[ts.ckks_vector(context, [feature]) for feature in item] for item in data]\n",
    "\n",
    "def encryptY(data, context):\n",
    "    return [ts.ckks_vector(context, [label]) for label in data]\n",
    "\n",
    "def decrypt(data):\n",
    "    return [item.decrypt() for item in data]\n",
    "\n",
    "seal_x_train = encryptX(X_train,ctx_training)\n",
    "seal_y_train = encryptY(y_train,ctx_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Netz zu trainieren gibt es zwei Möglichkeiten:\n",
    "* Nach jedem Trainingsschritt können die Gewichte entschlüsselt werden, durch den Besitzer des zugehörigen privaten Schlüssels, um dann wieder verschlüsselt zu werden. Dies würde erlauben die Berechnung so oft wie gewünscht durchzuführen. Das Problem hierbei ist, dass dies ein großer Zeit und Rechenaufwand mit sich bringt.\n",
    "* Die Gewichte müssen aber nicht nach jedem Trainingsschritt entschlüsselt werden und es kann für eine begrenzte Anzahl von Operationen trainiert werden. Diese Variante verringert aber die erreichbare Genauigkeit der trainierten Gewichte.\n",
    "* Als letzte Option, welche auch zu kein Ausstausch mit dem Datenbesitzer fällt ist das Bootstrapping, da damit unbegrenzt Berechnungen durchgeführt werden können"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kein Ausstausch mit Datenbesitzer\n",
    "---\n",
    "Um den Aufwand für den Datenbesitzer niedrig zu halten wird die zweite Variante implementiert und getestet. Hierfür wird die fit Funktion verändert, da nicht alle Vorgänge durchführbar sind mit verschlüsselten Daten. So können zum Beispiel die Gewichte nicht solange optimiert werden bis diese konvergieren, weshalb es nur wenige Trainingsphasen geben wird. Damit das Training trotzdem erfolgreich ist ist es hielfreich verschiedene Lernraten auszuprobieren, um die Gewichte gut zu approximieren. Diese Variante ist also pures Leveled HE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = [2, 1, 0.1, 0.01, 0.007, 0.003, 0.002, 0.001, 0.0009, 0.0007, 0.0003, 0.0001, 0.00001]\n",
    "\n",
    "def fit(x, y, context):\n",
    "\tregression = np.c_[x, np.ones(len(x))]\n",
    "\n",
    "\tweights = np.ones(regression.shape[1])\n",
    "\te_weights = np.array(encryptY(weights, context))\n",
    "\n",
    "\tall_weights = []\n",
    "\tfor learning_rate in hyperparameter:\n",
    "\t\thyper_weights = e_weights\n",
    "\t\tfor i in range(2):\n",
    "\t\t\ty_pred = regression @ hyper_weights.T\n",
    "\t\t\tdw = regression.T @ (y - y_pred)\n",
    "\t\t\thyper_weights = hyper_weights.T + (learning_rate * dw)\n",
    "\n",
    "\t\tall_weights.append((learning_rate, hyper_weights))\n",
    "\n",
    "\treturn all_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Training gibt also eine Liste an verschiedenen Gewichten aus für die unterschiedlichen Lernraten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = fit(seal_x_train, seal_y_train, ctx_training)\n",
    "\n",
    "e_weights = [[e_value.decrypt()[0] for e_value in e_tuple[1]] for e_tuple in all_weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die verschiedenen Versionen der Gewichte können nun einzelnen geprüft werden auf dem Testdatensatz. Dadurch kann bestimmt werden welche Lernrate für diese Aufgabe die Beste ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Gewichte sind die mit der Learning rate von 0.002\n"
     ]
    }
   ],
   "source": [
    "min = []\n",
    "for idx, learning_rate in enumerate(hyperparameter):\n",
    "    result = predict(e_weights[idx], X_test)\n",
    "    min.append(np.sqrt(mean_squared_error(y_test, result)))\n",
    "best_weight_idx = np.argmin(min)\n",
    "print(f\"Beste Gewichte sind die mit der Learning rate von {hyperparameter[best_weight_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die besten trainierten Gewichte haben eine höhere Abweichung als die Gewichte der unverschlüsselten Modelle. Es kommt aber nahe dran und kann noch weiter verbessert werden mit mehr Trainingsiterationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eingabe: [ 1.64384411 -0.13197948  1.16062026  0.52740629]\n",
      "Wahres Ergebnis: 2\n",
      "Ergebnis aus dem verschlüsselt trainierten Modell: 1.5720731776464807\n",
      "Ergebnis aus dem nicht verschlüsselt trainierten Modell: 1.5767759592337507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "index = randint(0, len(X_test)-1)\n",
    "print(f\"\"\"\n",
    "Eingabe: {X_test[index]}\n",
    "Wahres Ergebnis: {y_test[index]}\n",
    "Ergebnis aus dem verschlüsselt trainierten Modell: {predict(e_weights[best_weight_idx], X_test[index])}\n",
    "Ergebnis aus dem nicht verschlüsselt trainierten Modell: {predict(weights, X_test[index])}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.3158160197306934\n",
      "Mean Squared Error: 0.13016683310297522\n",
      "Mean Root Squared Error: 0.36078640925480443\n"
     ]
    }
   ],
   "source": [
    "result = predict(e_weights[best_weight_idx], X_test)\n",
    "meanError(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Unterschied im einzelnen Beispiel ist minimal und auch die eizelnen Metriken zeigen auf, dass das mit verschlüsselten Daten trainierte Modell zwar schlechter ist als die vorherig trainierten Modelle aber trotzdem in einem akzeptablen Bereich liegt.<br />\n",
    "Diese Ausführung der nicht interaktiven Variante ist aber nicht die einzig mögliche. Dies liegt daran, dass homomorph verschlüsselte Objekte (wenn dies implementiert ist in der Bibliothek) auch teilweise eine Möglichkeit besitzen das Rauschen zu verringern, um wieder mehr Operationen durchführen zu können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Austausch mit dem Datenbesitzer\n",
    "---\n",
    "Die erste Variante leidet unter den begrenzenten Operationen auf den verschlüsselten Gewichten. Vor allem wird dabei die Genauigkeit zugunsten der Laufzeit geopfert. In der zweiten Variante werden die Gewichte nach jeder Veränderung an den Datenbesitzer geschickt, damit diese entschlüsselt und neu verschlüsselt werden können. Damit ist eine unbegrenzte Anzahl an Operationen möglich und es kann fast wie auf unverschlüsselten Daten trainiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tenseal as ts\n",
    "\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 40]\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()\n",
    "\n",
    "seal_x_train = encryptX(X_train,ctx_training)\n",
    "seal_y_train = encryptY(y_train,ctx_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Während dem Training wird also nach jedem Epoch die Gewichte dem Datenbesitzer zugesendet. Dieser ent- und verschlüsselt diese wieder mit den gleichen Parameter wie am Anfang des Trainings. Dieser Vorgang wird mit dem Aufruf der folgenden Methode simuliert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_receive_weights(e_weights):\n",
    "\tweights = [item.decrypt() for item in e_weights]\n",
    "\treturn np.array([ts.ckks_vector(ctx_training, label) for label in weights])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der große Unterschied zum unverschlüsselten Training ist dabei, dass wir nicht aus der Ableitung der Gewichte ablesen können wie weit die Funktion noch optimiert werden muss. Dies liegt daran, da wir davon ausgehen, dass die Person, welche das Training ausführt, die entschlüsselten Gewichte erst zugesendet bekommt sobald das Training abgeschlossen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, y, epochs, learning_rate=0.00001):\n",
    "\tregression = np.c_[x, np.ones(len(x))]\n",
    "\n",
    "\tweights = np.ones(regression.shape[1])\n",
    "\te_weights = np.array(encryptY(weights, ctx_training))\n",
    "\n",
    "\tfor _ in range(epochs):\n",
    "\t\ty_pred = regression @ e_weights.T\n",
    "\t\tdw = regression.T @ (y - y_pred)\n",
    "\t\te_weights = e_weights.T + (learning_rate * dw)\n",
    "\t\te_weights = send_receive_weights(e_weights)\n",
    "\n",
    "\treturn [item.decrypt() for item in e_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_weights = fit(seal_x_train, seal_y_train, 200, 0.0001)\n",
    "e_weights = [e_weight[0] for e_weight in e_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eingabe: [-1.74885626  0.32841405 -1.39706395 -1.3154443 ]\n",
      "Wahres Ergebnis: 0\n",
      "Ergebnis aus dem verschlüsselt trainierten Modell: -0.009077952975548143\n",
      "Ergebnis aus dem nicht verschlüsselt trainierten Modell: -0.002625144189892792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = randint(0, len(X_test)-1)\n",
    "print(f\"\"\"\n",
    "Eingabe: {X_test[index]}\n",
    "Wahres Ergebnis: {y_test[index]}\n",
    "Ergebnis aus dem verschlüsselt trainierten Modell: {predict(e_weights, X_test[index])}\n",
    "Ergebnis aus dem nicht verschlüsselt trainierten Modell: {predict(weights, X_test[index])}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.1681699951761388\n",
      "Mean Squared Error: 0.06763102721143464\n",
      "Mean Root Squared Error: 0.26005966086926025\n"
     ]
    }
   ],
   "source": [
    "result = predict(e_weights, X_test)\n",
    "meanError(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie zu sehen ist an den Ergebnissen hat das mit Hilfe der anderen Variante trainierte Modell eine höhere Genauigkeit. Dies wäre also ein Kompromiss zwischen der Genauigkeit und der Laufzeit, da das immer wieder aufs neue verschlüsseln der Gewichte sehr aufwändig ist.<br />\n",
    "Als weitere Interaktive Version wäre es noch möglich das jeweilige Ergebnis eines Forward Schrittes zu entschlüsseln und damit das Netz zu trainieren. Dies würde die Laufzeit enorm verringern und würde die Eingabedaten nicht preisgeben, weil diese noch verschlüsselt sind und nicht für das eigentliche Training benötigt werden. Ob mit dieser Variante der Datenschutz komplett geboten ist ist fraglich."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('projektarbeit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f7bcc9c9e9fc7020bbd4d78b5067a4b842b19b8327d3657c3117d34f6877e4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
